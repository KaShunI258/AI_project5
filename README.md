# äººå·¥æ™ºèƒ½æœŸæœ«é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªåŸºäºæ•°æ®ä¸ºä¸­å¿ƒï¼ˆData-Centric AIï¼‰ç†å¿µçš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æé¡¹ç›®ã€‚æœ¬é¡¹ç›®ä¸ä»…ä»…ä¾èµ–æ¨¡å‹æ¶æ„çš„æ”¹è¿›ï¼Œæ›´é€šè¿‡å¼•å…¥å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆVLMï¼‰è¿›è¡Œå®šå‘æ•°æ®å¢å¼ºï¼ŒæˆåŠŸè§£å†³äº†å°æ ·æœ¬å¤šæ¨¡æ€ä»»åŠ¡ä¸­å¸¸è§çš„å›¾æ–‡å¼±ç›¸å…³å’Œç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚

## âœ¨ æ ¸å¿ƒäº®ç‚¹ (Highlights)

1.  **Data-Centric ç­–ç•¥**ï¼šä¸åŒäºä¼ ç»Ÿçš„å™ªå£°å¢å¼ºï¼Œæœ¬é¡¹ç›®åˆ©ç”¨ **Qwen-VL** ç”Ÿæˆå®¢è§‚å›¾ç‰‡æè¿°ï¼Œé€šè¿‡â€œå¤§æ¨¡å‹æ•™å°æ¨¡å‹â€çš„æ–¹å¼ï¼Œæ˜¾å¼åœ°ä¿®å¤äº†åŸå§‹æ•°æ®ä¸­è¯­ä¹‰ç¼ºå¤±çš„é—®é¢˜ã€‚
2.  **SOTA çº§æ¶æ„**ï¼šé‡‡ç”¨ **BERT (Text) + Swin Transformer V2 (Image)** ä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œç»“åˆ **Attention Fusion** æœºåˆ¶è¿›è¡Œç‰¹å¾èåˆã€‚
3.  **ä¸å¹³è¡¡å¤„ç†**ï¼šå¼•å…¥ **ACB Loss (Adaptive Class Balancing Loss)**ï¼ŒåŠ¨æ€è°ƒæ•´æƒé‡ï¼Œæ˜¾è‘—æå‡äº† Neutralï¼ˆéš¾æ ·æœ¬ï¼‰ç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚
4.  **å¼ºåŸºçº¿å¯¹æ¯”**ï¼šåœ¨ Phase 6 ä¸­ä¸ **CLIP (ViT-L/14)** è¿›è¡Œ Linear Probe å¯¹æ¯”ï¼Œè¯æ˜äº†â€œå…¨é‡å¾®è°ƒ+æ•°æ®å¢å¼ºâ€çš„å°æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä¼˜äºé€šç”¨çš„é¢„è®­ç»ƒå¤§æ¨¡å‹ã€‚

---

## ğŸ“‚ é¡¹ç›®ç»“æ„ (File Structure)

```text
AI_course_of_ECNU/
â”œâ”€â”€ dataset/                     # æ•°æ®é›†æ ¹ç›®å½•
â”‚   â”œâ”€â”€ data_audit.csv           # æ•°æ®å®¡è®¡ç»Ÿè®¡
â”‚   â”œâ”€â”€ train_cleaned.txt        # æ¸…æ´—åçš„è®­ç»ƒé›†ç´¢å¼•
â”‚   â”œâ”€â”€ test_without_label.txt   # æµ‹è¯•é›†ç´¢å¼•æ–‡ä»¶
â”‚   â””â”€â”€ data/                    # [æ ¸å¿ƒæ•°æ®] å­˜æ”¾æ‰€æœ‰ .jpg å›¾ç‰‡å’Œ .txt æ–‡æœ¬
â”œâ”€â”€ pretrained_models/           # [å…³é”®] é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ bert-base-uncased/       # BERT æƒé‡ç›®å½•
â”‚   â””â”€â”€ swinv2-base-patch4-window8-256/ # SwinV2 æƒé‡ç›®å½•
â”œâ”€â”€ phase0/                      # æ•°æ®é¢„å¤„ç†é˜¶æ®µ
â”‚   â”œâ”€â”€ data_cleaner.py          # æ•°æ®æ¸…æ´—è„šæœ¬
â”‚   â””â”€â”€ data_analysis.py         # æ•°æ®åˆ†å¸ƒåˆ†æ
â”œâ”€â”€ phase1/                      # Baseline æ­å»ºé˜¶æ®µ
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â”œâ”€â”€ utils/                   # å·¥å…·åŒ… (Config, Dataset)
â”‚   â””â”€â”€ results/                 # Phase 1 è¿è¡Œç»“æœ
â”œâ”€â”€ phase2/                      # æ¶æ„æœç´¢ä¸è¶…å‚ä¼˜åŒ–
â”‚   â”œâ”€â”€ run_phase2.py            # æœç´¢è„šæœ¬
â”‚   â”œâ”€â”€ search_hyperparam.py
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ phase3/                      # Loss å‡½æ•°æ¢ç´¢é˜¶æ®µ
â”‚   â”œâ”€â”€ run_phase3.py            # ä¸»è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ trainer.py               # æ”¯æŒ ACB Loss çš„è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ visualization_phase3.py
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ results/                 # å­˜æ”¾ Exp2_ACB_Loss_best.pth ç­‰
â”œâ”€â”€ phase4/                      # [æ ¸å¿ƒé˜¶æ®µ] VLM å¢å¼ºä¸æœ€ç»ˆæ¨¡å‹
â”‚   â”œâ”€â”€ run_phase4.py            # å…¨æµç¨‹ä¸»æ§è„šæœ¬
â”‚   â”œâ”€â”€ augmentations.py         # VLM API è°ƒç”¨ä¸å¢å¼ºé€»è¾‘
â”‚   â”œâ”€â”€ multimodel.py            # æœ€ç»ˆä¼˜åŒ–çš„æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ predict_test.py          # æµ‹è¯•é›†é¢„æµ‹è„šæœ¬
â”‚   â”œâ”€â”€ visualization_phase4_final.py # æ€§èƒ½æ¼”è¿›ç»˜å›¾
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ figures/                 # å­˜æ”¾ Fig4-1, 4-2, 4-3 ç­‰å›¾è¡¨
â”‚   â””â”€â”€ results/                 # å­˜æ”¾ Phase4_Augmentation_best.pth (æœ€ä¼˜æ¨¡å‹)
â”œâ”€â”€ phase5/                      # æ¨¡æ€æ¶ˆèå®éªŒ
â”‚   â”œâ”€â”€ run_phase5.py            # æ¶ˆèæ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ visualization_phase5_radar.py # é›·è¾¾å›¾ç»˜åˆ¶
â”‚   â”œâ”€â”€ multimodel.py            # æ”¯æŒ ablation_mode çš„æ¨¡å‹
â”‚   â”œâ”€â”€ Tab5-1_Modality_Ablation.csv # æ¶ˆèæ•°æ®è¡¨
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ phase6/                      # CLIP å¯¹æ¯”å®éªŒ
â”‚   â”œâ”€â”€ run_phase6.py            # CLIP è®­ç»ƒä¸å¯¹æ¯”ä¸»è„šæœ¬
â”‚   â”œâ”€â”€ clip_classifier.py       # CLIP Linear Probe æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ download_clip.py
â”‚   â”œâ”€â”€ figures/                 # å­˜æ”¾å¯¹æ¯”å›¾
â”‚	â”œâ”€â”€ pretrained_models/
â”‚	â”‚ â””â”€â”€ clip-vit-large-patch14-336/     # CLIP æƒé‡ç›®å½• (Phase 6)
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ predict.txt                  # æœ€ç»ˆæäº¤çš„æµ‹è¯•é›†é¢„æµ‹ç»“æœ
â”œâ”€â”€ requirements.txt             # é¡¹ç›®ä¾èµ–åº“åˆ—è¡¨
â””â”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

------

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```Bash
conda create -n multimodel python=3.11
conda activate multimodel
pip install -r requirements.txt
```

### 2. é¢„è®­ç»ƒæ¨¡å‹å‡†å¤‡

è¯·ä» Hugging Face æˆ–å…¶ä»–æ¸ é“ä¸‹è½½ä»¥ä¸‹æ¨¡å‹æƒé‡ï¼Œå¹¶æ”¾ç½®åœ¨ `pretrained_models/` ç›®å½•ä¸‹ï¼š

- `bert-base-uncased`
- `microsoft/swinv2-base-patch4-window8-256`

æ­¤å¤–ï¼Œ`openai/clip-vit-large-patch14-336` ä»… Phase 6 éœ€è¦ï¼Œå› æ­¤éœ€è¦æ”¾åœ¨`phase6/pretrained_models/`ã€‚

------

## ğŸƒâ€â™‚ï¸ è¿è¡Œæµç¨‹

æœ¬é¡¹ç›®æŒ‰ Phase é€æ­¥æ¨è¿›ï¼Œå»ºè®®æŒ‰é¡ºåºè¿è¡Œã€‚

### Phase 1-3: åŸºç¡€æ¶æ„ä¸ Loss æ¢ç´¢

è¿™éƒ¨åˆ†åŒ…å«åŸºç¡€ Baseline æ­å»ºã€ç‰¹å¾èåˆæ–¹å¼å¯¹æ¯”åŠ Loss å‡½æ•°ä¼˜åŒ–ã€‚

#### phase1

è¿™æ˜¯ç”ŸæˆåŸºçº¿æ ‡å‡†çš„å‘½ä»¤è¡Œã€‚

```bash
cd phase1
python main.py \
  --name Phase1_Baseline \
  --feature_fusion concat \
  --loss_type ce \
  --learning_rate 5e-5 \
  --dropout 0.1 \
  --num_epochs 15
```

#### phase2

æ‰§è¡Œèåˆæ–¹å¼æ¢ç´¢ï¼š

```bash
cd phase2
# è¯¥è„šæœ¬ä¼šè‡ªåŠ¨å¾ªç¯è¿è¡Œå¤šæ¬¡å®éªŒï¼Œå¹¶å°†ç»“æœæ±‡æ€»
python run_phase2.py
```

å¯¹æœ€ä¼˜èåˆæ–¹å¼è¿›è¡Œè¶…å‚æ•°æ¢ç´¢ï¼š

```bash
python search_hyperparam.py
```

#### phase3

```Bash
cd phase3
# è¿è¡Œ Exp2 (ä½¿ç”¨ ACB Loss è®­ç»ƒæœ€ä¼˜ Baseline)
python main.py --name Exp2_ACB_Loss --loss_type acb --feature_fusion attention_combine
```

*äº§å‡º*: `phase3/results/Exp2_ACB_Loss_best.pth` ï¼Œè¿™å°†ä½œä¸ºphase4çš„è®­ç»ƒèµ·ç‚¹ã€‚

### Phase 4: VLM å®šå‘å¢å¼ºä¸æœ€ç»ˆæ¨¡å‹

è¿™æ˜¯æœ¬é¡¹ç›®çš„æ ¸å¿ƒé˜¶æ®µï¼ŒåŒ…å«éš¾æ ·æœ¬æŒ–æ˜ã€VLM å¢å¼ºå’Œè¿ç§»å­¦ä¹ ã€‚

1. **é…ç½® API**: æ‰“å¼€ `phase4/run_phase4.py`ï¼Œéœ€è¦å¡«å…¥ ECNU Qwen-VL API Keyã€‚

2. **æ‰§è¡Œå…¨æµç¨‹**:

   ```Bash
   cd phase4
   python run_phase4.py
   ```

   *ç¨‹åºä¼šè‡ªåŠ¨æ‰§è¡Œï¼šåŠ è½½ Phase 3 æ¨¡å‹ -> æŒ–æ˜éš¾æ ·æœ¬ -> è°ƒç”¨ API å¢å¼º -> ç”Ÿæˆæ–°æ•°æ®é›† -> é‡æ–°å¾®è°ƒã€‚*

3. **å¯è§†åŒ–**:

   ```Bash
   python visualization_phase4_final.py
   ```

*äº§å‡º*: `phase4/results/Phase4_Augmentation_best.pth` ï¼Œä¹Ÿå°±æ˜¯æœ€ç»ˆæœ€ä¼˜æ¨¡å‹ã€‚

### Phase 5: æ¨¡æ€æ¶ˆèå®éªŒ

éªŒè¯æ–‡æœ¬å’Œå›¾åƒæ¨¡æ€å„è‡ªçš„è´¡çŒ®ã€‚

```Bash
cd phase5
# æ‰§è¡Œæ¶ˆèæ¨ç†
python run_phase5.py
# ç»˜åˆ¶é«˜çº§é›·è¾¾å›¾
python visualization_phase5_radar.py
```

### Phase 6: CLIP Baseline å¯¹æ¯”

å¯¹æ¯”æˆ‘ä»¬çš„æ¨¡å‹ä¸ CLIP (Linear Probe) çš„æ€§èƒ½ã€‚

```Bash
cd phase6
# è®­ç»ƒ CLIP å¹¶è¿›è¡Œå¯¹æ¯”è¯„ä¼°
python run_phase6.py
# å¾—åˆ°å¯è§†åŒ–ç»“æœ
python visualization.py
```

------

## ğŸ“Š å¦‚ä½•è·å¾—æµ‹è¯•é›†ç»“æœ

ä½¿ç”¨ Phase 4 è®­ç»ƒå‡ºçš„æœ€ä¼˜æ¨¡å‹å¯¹æ— æ ‡ç­¾æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ã€‚

1. ç¡®ä¿ä½ å·²ç»å®Œæˆäº† Phase 4 çš„è®­ç»ƒï¼Œå¹¶ä¸” `phase4/results/Phase4_Augmentation_best.pth` å­˜åœ¨ã€‚

2. è¿è¡Œé¢„æµ‹è„šæœ¬ï¼š

   ```Bash
   cd phase4
   python predict_test.py
   ```
   
3. **ç»“æœæ–‡ä»¶**: ç”Ÿæˆçš„æ–‡ä»¶ä½äº `phase4/predict.txt`ã€‚

   - æ ¼å¼ï¼š`guid,tag`
   - å†…å®¹ï¼šåŒ…å«æ‰€æœ‰æµ‹è¯•é›†æ ·æœ¬çš„é¢„æµ‹æ ‡ç­¾ï¼ˆpositive/neutral/negativeï¼‰ã€‚

------

## ğŸ“š å‚è€ƒèµ„æ–™

æœ¬é¡¹ç›®ä»£ç å®ç°å‚è€ƒäº†ä»¥ä¸‹è®ºæ–‡ï¼š

**è®ºæ–‡ (Papers):**

1. **BERT**: Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", NAACL 2019.
2. **Swin Transformer V2**: Liu et al., "Swin Transformer V2: Scaling Up Capacity and Resolution", CVPR 2022.
3. **CLIP**: Radford et al., "Learning Transferable Visual Models From Natural Language Supervision", ICML 2021.
4. **ACB Loss**: Cui et al., "Class-Balanced Loss Based on Effective Number of Samples", CVPR 2019.
5. **Qwen-VL**: Bai et al., "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond", 2023.

------

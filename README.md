# Multimodal Sentiment Analysis: A Data-Centric Approach

![Python](https://img.shields.io/badge/Python-3.11-blue?style=flat&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red?style=flat&logo=pytorch)
![Status](https://img.shields.io/badge/Status-Completed-success)
![Focus](https://img.shields.io/badge/Focus-Data--Centric%20AI-orange)

****

## ğŸ“– é¡¹ç›®ä»‹ç»

è¿™æ˜¯ä¸€ä¸ªåŸºäº **Data-Centric AIï¼ˆä»¥æ•°æ®ä¸ºä¸­å¿ƒï¼‰** ç†å¿µæ„å»ºçš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æé¡¹ç›®ã€‚é’ˆå¯¹å°æ ·æœ¬å¤šæ¨¡æ€ä»»åŠ¡ä¸­å¸¸è§çš„ **å›¾æ–‡å¼±ç›¸å…³ï¼ˆWeak Correlationï¼‰** å’Œ **ç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡ï¼ˆClass Imbalanceï¼‰** é—®é¢˜ï¼Œæœ¬é¡¹ç›®å¹¶æœªæ­¢æ­¥äºæ¨¡å‹æ¶æ„çš„å †å ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€å¥—åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼š

é€šè¿‡å¼•å…¥ **Qwen-VL** å¤šæ¨¡æ€å¤§æ¨¡å‹è¿›è¡Œ**è§†è§‰è¯­ä¹‰è’¸é¦ï¼ˆVisual Semantic Distillationï¼‰**ï¼Œå®ç°äº†â€œå¤§æ¨¡å‹æ•™å°æ¨¡å‹â€ï¼Œæ˜¾å¼ä¿®å¤äº†åŸå§‹æ•°æ®çš„è¯­ä¹‰ç¼ºå¤±ã€‚æœ€ç»ˆæ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸå†…ä¸ä»…è¶…è¶Šäº†å•çº¯çš„æ¶æ„ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ›´åœ¨ä¸ **CLIP (ViT-L/14)** çš„å¯¹æ¯”ä¸­å–å¾—äº†æ›´ä¼˜çš„ Weighted F1 åˆ†æ•°ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

* **ğŸ† SOTA çº§æ¶æ„è®¾è®¡**
  * é‡‡ç”¨ **BERT (Text) + Swin Transformer V2 (Image)** ä½œä¸ºå¼ºåŠ›éª¨å¹²ç½‘ç»œã€‚
  * å¯¹æ¯”å¤šç§èåˆç­–ç•¥ï¼Œæœ€ç»ˆç¡®ç«‹ **Attention Fusion** æœºåˆ¶ï¼Œå®ç°äº†æ¨¡æ€é—´çš„æ·±åº¦äº¤äº’ä¸ä¿¡æ¯ä¿ç•™ã€‚

* **ğŸ§  Data-Centric å¢å¼ºç­–ç•¥ (Phase 4)**
  * **éš¾æ ·æœ¬æŒ–æ˜**ï¼šè‡ªåŠ¨å®šä½ä½ç½®ä¿¡åº¦ä¸ Neutral æ··æ·†æ ·æœ¬ã€‚
  * **VLM å®šå‘ä¿®å¤**ï¼šåˆ©ç”¨ **Qwen-VL** ç”Ÿæˆå®¢è§‚å›¾ç‰‡æè¿°ï¼Œè§£å†³â€œå›¾ç‰‡æœ‰å†…å®¹ä½†æ–‡æœ¬æ— è¯­ä¹‰â€çš„ç‰¹å¾å¯¹é½éš¾é¢˜ã€‚
  * *æ•ˆæœï¼šNeutral F1 æå‡ 11.5%ï¼ŒWeighted F1 æå‡è‡³ 74.0%ã€‚*

* **âš–ï¸ è‡ªé€‚åº”ç±»åˆ«å¹³è¡¡ (Phase 3)**
  * å¼•å…¥ **ACB Loss (Adaptive Class Balancing Loss)**ã€‚
  * é€šè¿‡åŠ¨æ€è°ƒæ•´ Focal Term å’Œ Boundary Termï¼Œæ˜¾è‘—ç¼“è§£äº† Neutral ç±»åˆ«çš„è¯†åˆ«çŸ­æ¿ï¼Œæå‡äº†æ¨¡å‹çš„æ¦‚ç‡æ ¡å‡†æ€§ï¼ˆCalibrationï¼‰ã€‚

* **âš”ï¸ å¼ºåŸºçº¿å¯¹æ¯” (Phase 6)**
  * åœ¨ Linear Probe è®¾ç½®ä¸‹ä¸ **CLIP-ViT-Large** è¿›è¡Œå¯¹æ¯”ã€‚
  * ç»“æœè¯æ˜ï¼šâ€œç‰¹å®šé¢†åŸŸå¾®è°ƒ + VLM æ•°æ®å¢å¼ºâ€çš„å°æ¨¡å‹ç­–ç•¥ï¼Œåœ¨ç»†ç²’åº¦æƒ…æ„Ÿåˆ†ç±»ä¸Šä¼˜äºé€šç”¨çš„é¢„è®­ç»ƒå¤§æ¨¡å‹ã€‚

---

## ğŸ“Š æ€§èƒ½è¡¨ç°

åŸºäºæœ€ç»ˆæµ‹è¯•é›†ï¼ˆPhase 4 Best Modelï¼‰çš„å®éªŒæ•°æ®æ‘˜è¦ã€‚

### 1. æ€»ä½“æ€§èƒ½æ¼”è¿›

| å®éªŒé˜¶æ®µ    | æ–¹æ³•æè¿°              | Weighted F1 | Neutral F1 (éš¾æ ·æœ¬) | æå‡è¯´æ˜                 |
| :---------- | :-------------------- | :---------: | :-----------------: | :----------------------- |
| **Phase 1** | Baseline (Concat)     |    67.8%    |        33.3%        | åŸºç¡€åŸºçº¿                 |
| **Phase 2** | Architecture Search   |    68.7%    |        40.7%        | å¼•å…¥ Attention Fusion    |
| **Phase 3** | Loss Strategy         |    67.2%    |        35.5%        | å¼•å…¥ ACB Loss (æ›´å¹³è¡¡)   |
| **Phase 4** | **Data Augmentation** |  **74.0%**  |      **52.2%**      | **VLM å¢å¼º (æœ€ç»ˆ SOTA)** |

### 2. ä¸ CLIP å¤§æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹æ¶æ„            | Weighted F1 | Neutral F1 | ç»“è®º                 |
| :------------------ | :---------: | :--------: | :------------------- |
| **Ours (Phase 4)**  |  **0.740**  | **0.522**  | âœ… åœ¨ç‰¹å®šé¢†åŸŸæ›´ç²¾å‡†   |
| CLIP (Linear Probe) |    0.728    |   0.395    | é€šç”¨æ€§å¼ºä½†ç»†ç²’åº¦ä¸è¶³ |

> **æ¶ˆèå®éªŒç»“è®º**ï¼šé›·è¾¾å›¾åˆ†ææ˜¾ç¤ºï¼Œåœ¨ç»è¿‡ Phase 4 å¢å¼ºåï¼Œå›¾åƒæ¨¡æ€åœ¨æœ¬ä»»åŠ¡ä¸­çš„è´¡çŒ®åº¦å®é™…ä¸Šé«˜äºæ–‡æœ¬æ¨¡æ€ï¼ˆText Only F1 ä»… 0.527 vs Image Only 0.687ï¼‰ã€‚

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
AI_course_of_ECNU/
â”œâ”€â”€ dataset/                     # æ•°æ®é›†æ ¹ç›®å½•
â”‚   â”œâ”€â”€ data_audit.csv           # æ•°æ®å®¡è®¡ç»Ÿè®¡
â”‚   â”œâ”€â”€ train_cleaned.txt        # æ¸…æ´—åçš„è®­ç»ƒé›†ç´¢å¼•
â”‚   â”œâ”€â”€ test_without_label.txt   # æµ‹è¯•é›†ç´¢å¼•æ–‡ä»¶
â”‚   â””â”€â”€ data/                    # [æ ¸å¿ƒæ•°æ®] å­˜æ”¾æ‰€æœ‰ .jpg å›¾ç‰‡å’Œ .txt æ–‡æœ¬
â”œâ”€â”€ pretrained_models/           # [å…³é”®] é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ bert-base-uncased/       # BERT æƒé‡ç›®å½•
â”‚   â””â”€â”€ swinv2-base-patch4-window8-256/ # SwinV2 æƒé‡ç›®å½•
â”œâ”€â”€ phase0/                      # æ•°æ®é¢„å¤„ç†é˜¶æ®µ
â”‚   â”œâ”€â”€ data_cleaner.py          # æ•°æ®æ¸…æ´—è„šæœ¬
â”‚   â””â”€â”€ data_analysis.py         # æ•°æ®åˆ†å¸ƒåˆ†æ
â”œâ”€â”€ phase1/                      # Baseline æ­å»ºé˜¶æ®µ
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â”œâ”€â”€ utils/                   # å·¥å…·åŒ… (Config, Dataset)
â”‚   â””â”€â”€ results/                 # Phase 1 è¿è¡Œç»“æœ
â”œâ”€â”€ phase2/                      # æ¶æ„æœç´¢ä¸è¶…å‚ä¼˜åŒ–
â”‚   â”œâ”€â”€ run_phase2.py            # æœç´¢è„šæœ¬
â”‚   â”œâ”€â”€ search_hyperparam.py
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ phase3/                      # Loss å‡½æ•°æ¢ç´¢é˜¶æ®µ
â”‚   â”œâ”€â”€ run_phase3.py            # ä¸»è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ trainer.py               # æ”¯æŒ ACB Loss çš„è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ multimodel.py
â”‚   â”œâ”€â”€ visualization_phase3.py
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ results/                 # å­˜æ”¾ Exp2_ACB_Loss_best.pth ç­‰
â”œâ”€â”€ phase4/                      # [æ ¸å¿ƒé˜¶æ®µ] VLM å¢å¼ºä¸æœ€ç»ˆæ¨¡å‹
â”‚   â”œâ”€â”€ run_phase4.py            # å…¨æµç¨‹ä¸»æ§è„šæœ¬
â”‚   â”œâ”€â”€ augmentations.py         # VLM API è°ƒç”¨ä¸å¢å¼ºé€»è¾‘
â”‚   â”œâ”€â”€ multimodel.py            # æœ€ç»ˆä¼˜åŒ–çš„æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ predict_test.py          # æµ‹è¯•é›†é¢„æµ‹è„šæœ¬
â”‚   â”œâ”€â”€ visualization_phase4_final.py # æ€§èƒ½æ¼”è¿›ç»˜å›¾
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ figures/                 # å­˜æ”¾ Fig4-1, 4-2, 4-3 ç­‰å›¾è¡¨
â”‚   â””â”€â”€ results/                 # å­˜æ”¾ Phase4_Augmentation_best.pth (æœ€ä¼˜æ¨¡å‹)
â”œâ”€â”€ phase5/                      # æ¨¡æ€æ¶ˆèå®éªŒ
â”‚   â”œâ”€â”€ run_phase5.py            # æ¶ˆèæ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ visualization_phase5_radar.py # é›·è¾¾å›¾ç»˜åˆ¶
â”‚   â”œâ”€â”€ multimodel.py            # æ”¯æŒ ablation_mode çš„æ¨¡å‹
â”‚   â”œâ”€â”€ Tab5-1_Modality_Ablation.csv # æ¶ˆèæ•°æ®è¡¨
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ phase6/                      # CLIP å¯¹æ¯”å®éªŒ
â”‚   â”œâ”€â”€ run_phase6.py            # CLIP è®­ç»ƒä¸å¯¹æ¯”ä¸»è„šæœ¬
â”‚   â”œâ”€â”€ clip_classifier.py       # CLIP Linear Probe æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ download_clip.py
â”‚   â”œâ”€â”€ figures/                 # å­˜æ”¾å¯¹æ¯”å›¾
â”‚	â”œâ”€â”€ pretrained_models/
â”‚	â”‚ â””â”€â”€ clip-vit-large-patch14-336/     # CLIP æƒé‡ç›®å½• (Phase 6)
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ predict.txt                  # æœ€ç»ˆæäº¤çš„æµ‹è¯•é›†é¢„æµ‹ç»“æœ
â”œâ”€â”€ requirements.txt             # é¡¹ç›®ä¾èµ–åº“åˆ—è¡¨
â””â”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

------

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```Bash
conda create -n multimodel python=3.11
conda activate multimodel
pip install -r requirements.txt
```

### 2. é¢„è®­ç»ƒæ¨¡å‹å‡†å¤‡

è¯·ä» Hugging Face æˆ–å…¶ä»–æ¸ é“ä¸‹è½½ä»¥ä¸‹æ¨¡å‹æƒé‡ï¼Œå¹¶æ”¾ç½®åœ¨ `pretrained_models/` ç›®å½•ä¸‹ï¼š

- `bert-base-uncased`
- `microsoft/swinv2-base-patch4-window8-256`

æ­¤å¤–ï¼Œ`openai/clip-vit-large-patch14-336` ä»… Phase 6 éœ€è¦ï¼Œå› æ­¤éœ€è¦æ”¾åœ¨`phase6/pretrained_models/`ã€‚

------

## ğŸƒâ€â™‚ï¸ è¿è¡Œæµç¨‹

æœ¬é¡¹ç›®æŒ‰ Phase é€æ­¥æ¨è¿›ï¼Œå»ºè®®æŒ‰é¡ºåºè¿è¡Œã€‚

### Phase 1-3: åŸºç¡€æ¶æ„

è¿™éƒ¨åˆ†åŒ…å«åŸºç¡€ Baseline æ­å»ºã€ç‰¹å¾èåˆæ–¹å¼å¯¹æ¯”åŠ Loss å‡½æ•°ä¼˜åŒ–ã€‚

#### phase1ï¼šåŸºçº¿

è¿™æ˜¯ç”ŸæˆåŸºçº¿æ ‡å‡†çš„å‘½ä»¤è¡Œã€‚

```bash
cd phase1
python main.py \
  --name Phase1_Baseline \
  --feature_fusion concat \
  --loss_type ce \
  --learning_rate 5e-5 \
  --dropout 0.1 \
  --num_epochs 15
```

#### phase2ï¼šèåˆæ–¹å¼æ¢ç´¢

```bash
cd phase2
# è¯¥è„šæœ¬ä¼šè‡ªåŠ¨å¾ªç¯è¿è¡Œå¤šæ¬¡å®éªŒï¼Œå¹¶å°†ç»“æœæ±‡æ€»
python run_phase2.py
```

å¯¹æœ€ä¼˜èåˆæ–¹å¼è¿›è¡Œè¶…å‚æ•°æ¢ç´¢ï¼š

```bash
python search_hyperparam.py
```

#### phase3ï¼šACB_lossæ•ˆæœéªŒè¯

```Bash
cd phase3
# è¿è¡Œ Exp2 (ä½¿ç”¨ ACB Loss è®­ç»ƒæœ€ä¼˜ Baseline)
python main.py --name Exp2_ACB_Loss --loss_type acb --feature_fusion attention_combine
```

*äº§å‡º*: `phase3/results/Exp2_ACB_Loss_best.pth` ï¼Œè¿™å°†ä½œä¸ºphase4çš„è®­ç»ƒèµ·ç‚¹ã€‚

### Phase 4: VLM å®šå‘å¢å¼ºä¸æœ€ç»ˆæ¨¡å‹

è¿™æ˜¯æœ¬é¡¹ç›®çš„æ ¸å¿ƒé˜¶æ®µï¼ŒåŒ…å«éš¾æ ·æœ¬æŒ–æ˜ã€VLM å¢å¼ºå’Œè¿ç§»å­¦ä¹ ã€‚

1. **é…ç½® API**: æ‰“å¼€ `phase4/run_phase4.py`ï¼Œéœ€è¦å¡«å…¥ ECNU Qwen-VL API Keyã€‚

2. **æ‰§è¡Œå…¨æµç¨‹**:

   ```Bash
   cd phase4
   python run_phase4.py
   ```

   *ç¨‹åºä¼šè‡ªåŠ¨æ‰§è¡Œï¼šåŠ è½½ Phase 3 æ¨¡å‹ -> æŒ–æ˜éš¾æ ·æœ¬ -> è°ƒç”¨ API å¢å¼º -> ç”Ÿæˆæ–°æ•°æ®é›† -> é‡æ–°å¾®è°ƒã€‚*

3. **å¯è§†åŒ–**:

   ```Bash
   python visualization_phase4_final.py
   ```

*äº§å‡º*: `phase4/results/Phase4_Augmentation_best.pth` ï¼Œä¹Ÿå°±æ˜¯æœ€ç»ˆæœ€ä¼˜æ¨¡å‹ã€‚

### Phase 5: æ¨¡æ€æ¶ˆèå®éªŒ

éªŒè¯æ–‡æœ¬å’Œå›¾åƒæ¨¡æ€å„è‡ªçš„è´¡çŒ®ã€‚

```Bash
cd phase5
# æ‰§è¡Œæ¶ˆèæ¨ç†
python run_phase5.py
# ç»˜åˆ¶é«˜çº§é›·è¾¾å›¾
python visualization_phase5_radar.py
```

### Phase 6: CLIP Baseline å¯¹æ¯”

å¯¹æ¯”æˆ‘ä»¬çš„æ¨¡å‹ä¸ CLIP (Linear Probe) çš„æ€§èƒ½ã€‚

```Bash
cd phase6
# è®­ç»ƒ CLIP å¹¶è¿›è¡Œå¯¹æ¯”è¯„ä¼°
python run_phase6.py
# å¾—åˆ°å¯è§†åŒ–ç»“æœ
python visualization.py
```

------

## ğŸ“Š å¦‚ä½•è·å¾—æµ‹è¯•é›†ç»“æœ

ä½¿ç”¨ Phase 4 è®­ç»ƒå‡ºçš„æœ€ä¼˜æ¨¡å‹å¯¹æ— æ ‡ç­¾æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ã€‚

1. ç¡®ä¿ä½ å·²ç»å®Œæˆäº† Phase 4 çš„è®­ç»ƒï¼Œå¹¶ä¸” `phase4/results/Phase4_Augmentation_best.pth` å­˜åœ¨ã€‚

2. è¿è¡Œé¢„æµ‹è„šæœ¬ï¼š

   ```Bash
   cd phase4
   python predict_test.py
   ```
   
3. **ç»“æœæ–‡ä»¶**: ç”Ÿæˆçš„æ–‡ä»¶ä½äº `phase4/predict.txt`ã€‚

   - æ ¼å¼ï¼š`guid,tag`
   - å†…å®¹ï¼šåŒ…å«æ‰€æœ‰æµ‹è¯•é›†æ ·æœ¬çš„é¢„æµ‹æ ‡ç­¾ï¼ˆpositive/neutral/negativeï¼‰ã€‚

------

## ğŸ“š å‚è€ƒèµ„æ–™

æœ¬é¡¹ç›®ä»£ç å®ç°å‚è€ƒäº†ä»¥ä¸‹è®ºæ–‡ï¼š

**è®ºæ–‡ (Papers):**

1. **BERT**: Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", NAACL 2019.
2. **Swin Transformer V2**: Liu et al., "Swin Transformer V2: Scaling Up Capacity and Resolution", CVPR 2022.
3. **CLIP**: Radford et al., "Learning Transferable Visual Models From Natural Language Supervision", ICML 2021.
4. **ACB Loss**: Cui et al., "Class-Balanced Loss Based on Effective Number of Samples", CVPR 2019.
5. **Qwen-VL**: Bai et al., "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond", 2023.

------

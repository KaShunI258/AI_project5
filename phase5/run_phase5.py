import torch
import pandas as pd
import numpy as np
import os
from torch.utils.data import DataLoader, Subset
from transformers import BertTokenizer, AutoImageProcessor
from torchvision import transforms
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report
from sklearn.model_selection import StratifiedShuffleSplit

# å¼•ç”¨æœ¬åœ°æ¨¡å—
from utils.config import Config
from utils.dataload import MultimodalDataset
from multimodel import MultimodalModel

# === é…ç½® ===
# æ³¨æ„ï¼šè¿™é‡Œä¸¥æ ¼ä½¿ç”¨ä½ æŒ‡å®šçš„æ–‡ä»¶å
PHASE4_BEST_MODEL = "../phase4/results/Phase4_Augmentation_best.pth"
DATA_DIR = "../dataset/data"
# ä½¿ç”¨å¢å¼ºåçš„æ•°æ®ä½œä¸ºæ¥æºï¼Œä½†æˆ‘ä»¬åªå…³å¿ƒéªŒè¯é›†
TRAIN_FILE_AUG = "../dataset/train_phase4_augmented.txt" 

class Args:
    def __init__(self):
        # åŸºç¡€é…ç½®ä¿æŒä¸ Phase 4 ä¸€è‡´ï¼Œç¡®ä¿æ¨¡å‹èƒ½åŠ è½½
        self.data_dir = DATA_DIR
        self.train_file = TRAIN_FILE_AUG
        self.test_file = "dummy"
        self.result_file = "dummy"
        self.text_model_name = "../pretrained_models/bert-base-uncased"
        self.image_model_name = "../pretrained_models/swinv2-base-patch4-window8-256"
        self.batch_size = 32
        self.feature_fusion = 'attention_combine'
        self.text_dim = 256
        self.image_dim = 256
        self.num_classes = 3
        self.use_text = 1
        self.use_image = 1
        self.dropout = 0.1
        # å¿…é¡»æœ‰çš„å‚æ•°ï¼Œé˜²æ­¢ Config æŠ¥é”™
        self.learning_rate = 5e-5 
        self.num_epochs = 1
        self.val_ratio = 0.1
        self.early_stop_patience = 4
        self.loss_type = 'acb'
        self.use_sampler = False
        self.wandb = False
        self.name = "Phase5_Ablation"
        self.project_name = "Phase5"
        self.log_iteration = 10

def evaluate_model(model, loader, config, mode_name):
    """åœ¨æŒ‡å®šæ¶ˆèæ¨¡å¼ä¸‹è¯„ä¼°æ¨¡å‹"""
    print(f"\nğŸ” Evaluating Mode: [{mode_name}] ...")
    
    # åŠ¨æ€è®¾ç½®æ¶ˆèæ¨¡å¼
    config.ablation_mode = mode_name
    model.config.ablation_mode = mode_name # ç¡®ä¿æ¨¡å‹å†…éƒ¨èƒ½è¯»åˆ°
    
    model.eval()
    all_preds = []
    all_labels = []
    
    tokenizer = BertTokenizer.from_pretrained(config.text_model_name)
    
    with torch.no_grad():
        for texts, images, labels in loader:
            encoded_texts = tokenizer(list(texts), padding=True, truncation=True, max_length=128, return_tensors="pt").to(config.device)
            images = images.to(config.device)
            
            # æ¨¡å‹ forward ä¼šæ ¹æ® config.ablation_mode è‡ªåŠ¨æŠŠå¯¹åº”ç‰¹å¾ç½®é›¶
            outputs = model(encoded_texts, images)
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            
            all_preds.extend(preds)
            all_labels.extend(labels.numpy())
            
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    acc = accuracy_score(all_labels, all_preds)
    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)
    
    # è·å– Neutral (Label=1) çš„ F1
    report = classification_report(all_labels, all_preds, output_dict=True, zero_division=0)
    neutral_f1 = report['1']['f1-score']
    
    print(f"   -> Acc: {acc:.4f} | F1: {f1:.4f} | Neu_F1: {neutral_f1:.4f}")
    
    return {
        "Modality": mode_name,
        "Accuracy": acc,
        "Precision": p,
        "Recall": r,
        "Weighted F1": f1,
        "Neutral F1": neutral_f1
    }

def main():
    print("ğŸš€ Starting Phase 5: Modality Ablation Study...")
    os.makedirs("results", exist_ok=True)
    
    # 1. å‡†å¤‡æ•°æ®å’Œæ¨¡å‹
    args = Args()
    config = Config(args)
    
    # åŠ è½½æ•°æ® (ä½¿ç”¨ä¸ Phase 4 ä¸€è‡´çš„åˆ’åˆ†æ–¹å¼ï¼Œä¿è¯éªŒè¯é›†æ˜¯å…¬å¹³çš„)
    image_processor = AutoImageProcessor.from_pretrained(config.image_model_name)
    transform = transforms.Compose([
        transforms.Resize((256, 256)), transforms.ToTensor(),
        transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
    ])
    
    full_dataset = MultimodalDataset(config.data_dir, config.train_file, transform, is_train=True)
    labels = full_dataset.labels
    sss = StratifiedShuffleSplit(n_splits=1, test_size=config.val_ratio, random_state=42) # å›ºå®šç§å­42
    _, val_idx = next(sss.split(np.zeros(len(labels)), labels))
    
    val_subset = Subset(full_dataset, val_idx)
    val_loader = DataLoader(val_subset, batch_size=config.batch_size, shuffle=False, num_workers=4)
    
    # åŠ è½½æ¨¡å‹
    model = MultimodalModel(config).to(config.device)
    if os.path.exists(PHASE4_BEST_MODEL):
        print(f"âœ… Loading weights from {PHASE4_BEST_MODEL}")
        model.load_state_dict(torch.load(PHASE4_BEST_MODEL, map_location=config.device))
    else:
        print(f"âŒ Error: Model file not found at {PHASE4_BEST_MODEL}")
        return

    # 2. æ‰§è¡Œä¸‰æ¬¡å®éªŒ
    results = []
    
    # (1) Text+Image (å®Œæ•´æ¨¡å‹)
    res_full = evaluate_model(model, val_loader, config, mode_name="none") # noneè¡¨ç¤ºä¸æ¶ˆè
    res_full["Modality"] = "Text + Image (Full)" # æ”¹ä¸ªå¥½å¬çš„åå­—
    results.append(res_full)
    
    # (2) Text-only (å±è”½å›¾åƒ)
    res_text = evaluate_model(model, val_loader, config, mode_name="text_only")
    res_text["Modality"] = "Text Only"
    results.append(res_text)
    
    # (3) Image-only (å±è”½æ–‡æœ¬)
    res_image = evaluate_model(model, val_loader, config, mode_name="image_only")
    res_image["Modality"] = "Image Only"
    results.append(res_image)
    
    # 3. ä¿å­˜å¹¶å±•ç¤ºè¡¨æ ¼
    df = pd.DataFrame(results)
    # è°ƒæ•´åˆ—é¡ºåº
    cols = ["Modality", "Accuracy", "Precision", "Recall", "Weighted F1", "Neutral F1"]
    df = df[cols]
    
    print("\nğŸ† Tab5-1: Modality Ablation Table")
    print(df.to_string(index=False))
    
    df.to_csv("results/Tab5-1_Modality_Ablation.csv", index=False)
    print("\nâœ… Results saved to results/Tab5-1_Modality_Ablation.csv")

if __name__ == "__main__":
    main()
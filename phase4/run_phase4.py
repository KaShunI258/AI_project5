import torch
import pandas as pd
import os
import shutil
import random  # [æ–°å¢] ç”¨äºéšæœºé‡‡æ ·
from torch.utils.data import DataLoader
from transformers import BertTokenizer, AutoImageProcessor
from torchvision import transforms

from utils.config import Config
from utils.dataload import MultimodalDataset
from multimodel import MultimodalModel
from trainer import MultimodalTrainer
from augmentations import DataAugmenter, VLMAugmenter

# === é…ç½® ===
# ç¡®ä¿è¿™é‡ŒæŒ‡å‘ä½ åˆšæ‰é‡æ–°ç”Ÿæˆçš„ Phase 3 æ¨¡å‹è·¯å¾„
PHASE3_BEST_MODEL = "../phase3/results/Exp2_ACB_Loss_best.pth" 
DATA_DIR = "../dataset/data"
TRAIN_FILE = "../dataset/train_cleaned.txt"
NEW_TRAIN_FILE = "../dataset/train_phase4_augmented.txt"

def identify_hard_samples(config, model_path):
    """
    æ­¥éª¤ 1: ä½¿ç”¨ Phase 3 æ¨¡å‹æ‰«æè®­ç»ƒé›†ï¼Œæ‰¾å‡º 'éš¾æ ·æœ¬'
    å®šä¹‰ï¼šé¢„æµ‹é”™è¯¯ æˆ– æ­£ç¡®ä½†ç½®ä¿¡åº¦ä½ (<0.6) çš„æ ·æœ¬
    """
    print("ğŸ” Scanning training set for Hard Samples...")
    
    tokenizer = BertTokenizer.from_pretrained(config.text_model_name)
    image_processor = AutoImageProcessor.from_pretrained(config.image_model_name)
    transform = transforms.Compose([
        transforms.Resize((256, 256)), transforms.ToTensor(),
        transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
    ])
    
    # åŠ è½½è®­ç»ƒé›† (ä¸ shuffle, æ–¹ä¾¿ç´¢å¼•å¯¹åº”)
    dataset = MultimodalDataset(config.data_dir, config.train_file, transform, is_train=True)
    loader = DataLoader(dataset, batch_size=32, shuffle=False)
    
    model = MultimodalModel(config).to(config.device)
    # åŠ è½½æƒé‡
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
    else:
        raise FileNotFoundError(f"Model file not found: {model_path}")
        
    model.eval()
    
    hard_samples = []
    
    with torch.no_grad():
        for i, (texts, images, labels) in enumerate(loader):
            texts = tokenizer(list(texts), padding=True, truncation=True, max_length=128, return_tensors="pt").to(config.device)
            images = images.to(config.device)
            
            outputs = model(texts, images)
            probs = torch.softmax(outputs, dim=1)
            confidences, preds = torch.max(probs, dim=1)
            
            for j in range(len(labels)):
                true_label = labels[j].item()
                pred_label = preds[j].item()
                conf = confidences[j].item()
                
                global_idx = i * 32 + j
                if global_idx < len(dataset.df):
                    guid = str(dataset.df.iloc[global_idx]['guid'])
                    
                    # åˆ¤å®šæ¡ä»¶ï¼šåˆ†é”™ æˆ– (æ˜¯Neutralä½†ç½®ä¿¡åº¦ä½)
                    is_wrong = (true_label != pred_label)
                    is_weak_neutral = (true_label == 1 and conf < 0.6)
                    
                    if is_wrong or is_weak_neutral:
                        hard_samples.append(guid)
                    
    print(f"Found {len(hard_samples)} total hard samples.")
    return hard_samples

def main():
    # === å®Œå–„åçš„å‚æ•°é…ç½® ===
    class Args:
        def __init__(self):
            # è·¯å¾„
            self.data_dir = DATA_DIR
            self.train_file = TRAIN_FILE
            self.test_file = "../dataset/test_without_label.txt"
            self.result_file = "result_phase4.txt" # [Fix] è¡¥å…¨å‚æ•°
            
            # æ¨¡å‹è·¯å¾„
            self.text_model_name = "../pretrained_models/bert-base-uncased"
            self.image_model_name = "../pretrained_models/swinv2-base-patch4-window8-256"
            
            # è®­ç»ƒå‚æ•°
            self.batch_size = 32
            self.learning_rate = 5e-5
            self.num_epochs = 15
            self.dropout = 0.1
            self.early_stop_patience = 4 # [Fix] è¡¥å…¨å‚æ•°
            self.val_ratio = 0.1         # [Fix] è¡¥å…¨å‚æ•°
            
            # æ¨¡å‹ç»“æ„
            self.feature_fusion = 'attention_combine'
            self.text_dim = 256
            self.image_dim = 256
            self.num_classes = 3
            self.use_text = 1
            self.use_image = 1
            
            # ç­–ç•¥å‚æ•°
            self.loss_type = 'acb'
            self.use_sampler = False
            self.alpha = 1.0
            self.beta = 0.1
            self.neural_init_weight = 1.0
            
            # å…¶ä»–
            self.wandb = False
            self.name = "Phase4_Augmentation"
            self.project_name = "Phase4"
            self.log_iteration = 10

    args = Args()
    config = Config(args)
    
    # 1. è¯†åˆ« Bad Cases
    hard_guids = identify_hard_samples(config, PHASE3_BEST_MODEL)
    
    # === [å…³é”®ä¿®æ”¹] éšæœºé‡‡æ · 25% ===
    sample_ratio = 0.25
    num_to_select = int(len(hard_guids) * sample_ratio)
    # è‡³å°‘é€‰ 1 ä¸ªï¼Œé˜²æ­¢æŠ¥é”™
    num_to_select = max(1, num_to_select)
    
    print(f"ğŸ“‰ Downsampling: Selecting {num_to_select} samples ({sample_ratio*100}%) from {len(hard_guids)} hard cases due to API limits.")
    
    selected_guids = random.sample(hard_guids, num_to_select)
    # ============================
    
    # 2. æ‰§è¡Œ VLM å¢å¼º
    # âš ï¸ è¯·åœ¨è¿™é‡Œå¡«å…¥ä½ çœŸå®çš„ Key âš ï¸
    API_KEY = "sk-ee3a6bcdb0e442be9259d84599b03675" 
    
    vlm_augmenter = VLMAugmenter(api_key=API_KEY)
    vlm_augmenter.augment_dataset(selected_guids, DATA_DIR, NEW_TRAIN_FILE)
    
    # 3. ä½¿ç”¨å¢å¼ºåçš„æ•°æ®é›†é‡æ–°è®­ç»ƒ
    print("\nğŸš€ Retraining with Augmented Data...")
    config.train_file = NEW_TRAIN_FILE # åˆ‡æ¢ä¸ºæ–°æ•°æ®é›†
    
    # é‡æ–°åˆå§‹åŒ–ç»„ä»¶
    tokenizer = BertTokenizer.from_pretrained(config.text_model_name)
    image_processor = AutoImageProcessor.from_pretrained(config.image_model_name)
    
    # é‡æ–°æ„å»ºæ¨¡å‹
    model = MultimodalModel(config)
    
    # é€‰æ‹©å¾®è°ƒç­–ç•¥ï¼šåŠ è½½ Phase 3 æƒé‡ä½œä¸ºèµ·ç‚¹
    print(f"Loading weights from {PHASE3_BEST_MODEL} for finetuning...")
    if os.path.exists(PHASE3_BEST_MODEL):
        model.load_state_dict(torch.load(PHASE3_BEST_MODEL))
    else:
        print("Warning: Phase 3 weights not found, training from scratch.")
    
    trainer = MultimodalTrainer(model, tokenizer, config)
    
    # æ•°æ®åŠ è½½
    transform = transforms.Compose([
        transforms.Resize((256, 256)), transforms.ToTensor(),
        transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
    ])
    
    full_dataset = MultimodalDataset(config.data_dir, config.train_file, transform, is_train=True)
    
    # åˆ’åˆ†éªŒè¯é›†
    from sklearn.model_selection import StratifiedShuffleSplit
    import numpy as np
    labels = full_dataset.labels
    sss = StratifiedShuffleSplit(n_splits=1, test_size=config.val_ratio, random_state=config.seed)
    train_idx, val_idx = next(sss.split(np.zeros(len(labels)), labels))
    
    from torch.utils.data import Subset
    train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=config.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=config.batch_size, shuffle=False, num_workers=4)
    
    trainer.train(train_loader, val_loader)
    
    # # ç»“æŸå‰å¼ºåˆ¶ä¿å­˜ Phase 4 æœ€ç»ˆæ¨¡å‹
    # torch.save(model.state_dict(), "results/Phase4_Best.pth")
    # print("Phase 4 Done. Model saved to results/Phase4_Best.pth")

if __name__ == "__main__":
    main()
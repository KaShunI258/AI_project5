import os
import torch
import pandas as pd
from tqdm import tqdm
from PIL import Image
from transformers import BertTokenizer, AutoImageProcessor
from torchvision import transforms

# å¼•ç”¨æœ¬åœ°æ¨¡å—
from utils.config import Config
from utils.dataload import MultimodalDataset  # <--- ç”¨å®ƒæ¥è·å–æ­£ç¡®çš„æ ‡ç­¾æ˜ å°„
from multimodel import MultimodalModel

# === é…ç½®è·¯å¾„ ===
MODEL_PATH = "results/Phase4_Augmentation_best.pth"
DATA_DIR = "../dataset/data"
TRAIN_FILE = "../dataset/train_cleaned.txt"       # ç”¨æ¥è·å–æ­£ç¡®çš„ label map
TEST_FILE = "../dataset/test_without_label.txt"
OUTPUT_FILE = "predict.txt"

class Args:
    """æ¨¡æ‹Ÿé…ç½®å‚æ•°"""
    def __init__(self):
        self.text_model_name = "../pretrained_models/bert-base-uncased"
        self.image_model_name = "../pretrained_models/swinv2-base-patch4-window8-256"
        self.feature_fusion = 'attention_combine'
        self.text_dim = 256
        self.image_dim = 256
        self.num_classes = 3
        self.dropout = 0.1
        self.use_text = 1
        self.use_image = 1
        # è·¯å¾„å ä½
        self.data_dir = DATA_DIR
        self.train_file = TRAIN_FILE
        self.test_file = "dummy"
        self.result_file = "dummy"
        # å…¶ä»–å‚æ•°
        self.batch_size = 1
        self.learning_rate = 1e-5
        self.num_epochs = 1
        self.val_ratio = 0.1
        self.early_stop_patience = 1
        self.loss_type = 'ce'
        self.use_sampler = False
        self.wandb = False
        self.name = "Inference"
        self.project_name = "Inference"
        self.log_iteration = 10

def read_text_file(guid):
    txt_path = os.path.join(DATA_DIR, f"{guid}.txt")
    if os.path.exists(txt_path):
        with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read().strip()
        return content
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ‰“å°è­¦å‘Š
    # print(f"Warning: Text not found for {guid}")
    return ""

def read_image_file(guid):
    img_path = os.path.join(DATA_DIR, f"{guid}.jpg")
    if not os.path.exists(img_path):
        img_path = os.path.join(DATA_DIR, f"{guid}.png")
    
    if os.path.exists(img_path):
        try:
            image = Image.open(img_path).convert('RGB')
            return image
        except:
            pass
    # æ‰“å°è­¦å‘Šï¼Œè¿™æ˜¯å…³é”®è°ƒè¯•ä¿¡æ¯
    print(f"âš ï¸ Warning: Image not found for guid [{guid}]. Input will be black!")
    return Image.new('RGB', (224, 224), (0, 0, 0))

def main():
    print("ğŸš€ Starting Prediction (Fixed Version)...")
    
    args = Args()
    config = Config(args)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    config.device = device

    # 1. è‡ªåŠ¨è·å–æ­£ç¡®çš„ Label Map
    # æˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªä¸´æ—¶ Datasetï¼Œåˆ©ç”¨å®ƒçš„é€»è¾‘æ¥è§£æ label é¡ºåº
    print("ğŸ” Detecting correct label mapping from training file...")
    temp_dataset = MultimodalDataset(config.data_dir, config.train_file, transform=None, is_train=True)
    
    # MultimodalDataset é€šå¸¸ä¼šæœ‰ label_map å±æ€§ï¼Œæˆ–è€…æˆ‘ä»¬æ ¹æ® labels æ¨å¯¼
    # å‡è®¾ dataset.label_map å­˜åœ¨ï¼š{'negative': 0, 'neutral': 1, 'positive': 2}
    # æˆ‘ä»¬éœ€è¦åè½¬å®ƒï¼š{0: 'negative', ...}
    if hasattr(temp_dataset, 'label_map'):
        label_map = temp_dataset.label_map
        id2label = {v: k for k, v in label_map.items()}
    else:
        # å¦‚æœæ²¡æœ‰ç›´æ¥å±æ€§ï¼ŒæŒ‰å­—æ¯æ’åºé‡æ–°ç”Ÿæˆä¸€éï¼ˆè¿™æ˜¯ MultimodalDataset çš„é€šç”¨é€»è¾‘ï¼‰
        unique_labels = sorted(list(set(temp_dataset.labels_str))) # å‡è®¾ labels_str å­˜äº†åŸå§‹æ–‡æœ¬
        # å¦‚æœ dataset æ²¡å­˜ labels_strï¼Œæˆ‘ä»¬ç›´æ¥ç¡¬ç¼–ç æœ€å¸¸è§çš„é€»è¾‘ï¼š
        # æ ¹æ®ç»éªŒï¼ŒPhase ä»£ç é€šå¸¸ä½¿ç”¨ sorted list
        print("âš ï¸ dataset.label_map not found, using Sorted Default: ['negative', 'neutral', 'positive']")
        id2label = {0: 'negative', 1: 'neutral', 2: 'positive'}
        
    print(f"âœ… Label Mapping: {id2label}")

    # 2. åŠ è½½æ¨¡å‹
    tokenizer = BertTokenizer.from_pretrained(config.text_model_name)
    image_processor = AutoImageProcessor.from_pretrained(config.image_model_name)
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
    ])

    model = MultimodalModel(config).to(device)
    if os.path.exists(MODEL_PATH):
        print(f"âœ… Loading weights from {MODEL_PATH}")
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    else:
        print(f"âŒ Model file not found: {MODEL_PATH}")
        return
    model.eval()

    # 3. è¯»å–æµ‹è¯•é›†
    df = pd.read_csv(TEST_FILE)
    print(f"Loaded {len(df)} samples.")

    results = []

    with torch.no_grad():
        for index, row in tqdm(df.iterrows(), total=len(df)):
            # === [æ ¸å¿ƒä¿®å¤] å¼ºåˆ¶è½¬æ¢ä¸ºæ•´æ•°å†è½¬å­—ç¬¦ä¸²ï¼Œå»é™¤ '.0' ===
            raw_guid = row['guid']
            try:
                # å…¼å®¹ float (8.0), int (8), string ("8.0")
                guid = str(int(float(raw_guid))) 
            except:
                guid = str(raw_guid)
            # =================================================
            
            # æ•°æ®è¯»å–
            text_content = read_text_file(guid)
            raw_image = read_image_file(guid)
            
            # é¢„å¤„ç†
            encoded_text = tokenizer([text_content], padding='max_length', truncation=True, max_length=128, return_tensors="pt").to(device)
            image_tensor = transform(raw_image).unsqueeze(0).to(device)
            
            # æ¨ç†
            outputs = model(encoded_text, image_tensor)
            pred_idx = torch.argmax(outputs, dim=1).item()
            
            # æ˜ å°„
            pred_label = id2label[pred_idx]
            
            results.append({'guid': guid, 'tag': pred_label})

    # 4. ä¿å­˜
    output_df = pd.DataFrame(results)
    output_df.to_csv(OUTPUT_FILE, index=False)
    
    print(f"\nâœ… Prediction done! Saved to {OUTPUT_FILE}")
    print("Preview:")
    print(output_df.head())
    
    # ç®€å•ç»Ÿè®¡
    print("\nLabel Distribution:")
    print(output_df['tag'].value_counts())

if __name__ == "__main__":
    main()